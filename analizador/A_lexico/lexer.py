import ply.lex as lex

# Definici칩n de los nombres de los tokens que el lexer reconocer치
tokens = (
    'NODO', 'ELIMINAR_NODO', 'ARISTA', 'ELIMINAR_ARISTA', 'PESO', 'RUTA_MINIMA', 'NO_D',
    'ID', 'NUMBER', 'LPAREN', 'RPAREN', 'COMMA', 'SEMICOLON'
)

# Diccionario de palabras reservadas y sus tokens correspondientes
reserved = {
    'nodo': 'NODO',
    'eliminar_nodo': 'ELIMINAR_NODO',
    'arista': 'ARISTA',
    'eliminar_arista': 'ELIMINAR_ARISTA',
    'peso': 'PESO',
    'ruta_minima': 'RUTA_MINIMA',
    'no_d': 'NO_D'
}

# Definiciones de tokens simples usando expresiones regulares
t_LPAREN    = r'\('
t_RPAREN    = r'\)'
t_COMMA     = r','
t_SEMICOLON = r';'

# Funci칩n para reconocer identificadores y palabras reservadas
def t_ID(t):
    r'[A-Za-z][A-Za-z0-9_]*'
    t.type = reserved.get(t.value.lower(), 'ID')  
    return t

# Funci칩n para reconocer n칰meros
def t_NUMBER(t):
    r'\d+'  
    t.value = int(t.value)  
    return t

# Funci칩n para manejar nuevas l칤neas
def t_newline(t):
    r'\n+'
    t.lexer.lineno += len(t.value)

# Ignorar espacios y tabulaciones
t_ignore = ' \t'

# Comentarios de una l칤nea
def t_COMMENT(t):
    r'//.*'  
    pass

# Comentarios multil칤nea
def t_COMMENT_BLOCK(t):
    r'/\*.*?\*/'  
    pass

# Funci칩n para manejar errores l칠xicos
# Funci칩n para manejar errores l칠xicos
def t_error(t):
    global errores_lexicograficos

    # Evitar error si t.lineno o t.lexpos no est치n definidos
    linea = t.lineno if hasattr(t, 'lineno') else "Desconocida"
    posicion = t.lexpos if hasattr(t, 'lexpos') else "Desconocida"

    mensaje_error = f"游띔 Error l칠xico en l칤nea {linea}, posici칩n {posicion}: Car치cter inv치lido '{t.value[0]}'"
    print(mensaje_error)

    # Obtener contexto de la l칤nea de error
    line_start = max(t.lexer.lexdata.rfind('\n', 0, t.lexpos) + 1, 0)  
    line_end = t.lexer.lexdata.find('\n', t.lexpos)
    if line_end == -1: 
        line_end = len(t.lexer.lexdata)  

    line = t.lexer.lexdata[line_start:line_end] if hasattr(t.lexer, 'lexdata') else "No disponible"

    # Crear mensaje detallado
    error_detalle = {
        "linea": linea,
        "posicion": posicion,
        "caracter": t.value[0],
        "mensaje": "Car치cter inv치lido en el c칩digo fuente.",
        "contexto": line
    }

    # Agregar error a la lista global
    errores_lexicograficos.append(error_detalle)

    # Mostrar la l칤nea donde ocurri칩 el error
    print(f"  L칤nea del error: {line}")
    print(f"  {' ' * (posicion - line_start + 17)}^")    

    # Marcar error_ocurrido como True
    t.lexer.error_ocurrido = True  # Establecer bandera de error

    # No lanzar excepci칩n, solo continuar con el siguiente car치cter
    t.lexer.skip(1)  # Ignorar el car치cter inv치lido y continuar el an치lisis

# Crear una instancia del lexer
lexer = lex.lex()

# Funci칩n para analizar el c칩digo de entrada y devolver una lista de tokens
def analizar_codigo(data):
    global errores_lexicograficos
    errores_lexicograficos = []  # Resetear errores
    if not data:  # Verificar si la entrada est치 vac칤a
        print("游뛂 La entrada est치 vac칤a. No se encontraron tokens.")
        return []  # Regresar una lista vac칤a

    lexer.lineno = 1
    lexer.input(data)
    lexer.error_ocurrido = False  # Inicializar bandera de error
    tokens_list = []
    
    # Procesar cada token en el c칩digo
    while True:
        tok = lexer.token()
        if not tok:
            break  # No m치s tokens
        tokens_list.append(tok)

    # Mostrar mensaje de 칠xito o error solo al final del proceso
    if lexer.error_ocurrido:
        print("丘멆잺 El an치lisis l칠xico termin칩 con errores.")
    else:
        print("九덢잺 El an치lisis l칠xico se complet칩 correctamente.")
    
    return tokens_list, errores_lexicograficos

# C칩digo principal para probar el lexer
if __name__ == "__main__":
    # Ejemplo de c칩digo v치lido
    print("\n游늷 An치lisis L칠xico:")
    codigo_prueba = "nodo(a)\nnodo(@)"
    tokens = analizar_codigo(codigo_prueba)
    print("\n游늶 Lista de Tokens:")
    for token in tokens:
        print(f"Tipo: {token.type}, Valor: {token.value}, L칤nea: {token.lineno}, Posici칩n: {token.lexpos}")
